{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b20c91",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e86314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Define paths based on environment\n",
    "if Path(\"/kaggle\").exists():\n",
    "    os.environ[\"AMBIENTE\"] = \"KAGGLE\"\n",
    "    os.environ[\"TENSORBOARD_NO_TF\"] = \"1\"\n",
    "\n",
    "    PATH_DATASET = Path(\"/kaggle/working/STROKE_PREDICTION\")\n",
    "    PATH_CODE = PATH_DATASET / \"src\"\n",
    "    PATH_OUTPUT_DIR = PATH_DATASET / \"outputs\"\n",
    "elif Path(\"/content\").exists():\n",
    "    os.environ[\"AMBIENTE\"] = \"COLAB\"\n",
    "    PATH_DATASET = Path(\"/content/DELETAR\")\n",
    "    PATH_CODE = PATH_DATASET / \"src\"\n",
    "    PATH_OUTPUT_DIR = PATH_DATASET / \"outputs\"\n",
    "else:\n",
    "    os.environ[\"AMBIENTE\"] = \"LOCAL\"\n",
    "    PATH_CODE = Path.cwd()\n",
    "    PATH_DATASET = PATH_CODE.parent\n",
    "    PATH_OUTPUT_DIR = PATH_DATASET / \"outputs\"\n",
    "\n",
    "\n",
    "# Check if installation has been done\n",
    "INSTALL_MARKER = PATH_DATASET / \".install_complete\"\n",
    "\n",
    "try:\n",
    "    if not INSTALL_MARKER.exists():\n",
    "        # Install uv\n",
    "        pass\n",
    "        !pip install uv\n",
    "\n",
    "        # Environment-specific setup\n",
    "        if os.environ[\"AMBIENTE\"] == \"KAGGLE\":\n",
    "            import kaggle_secrets\n",
    "\n",
    "            user_secrets = kaggle_secrets.UserSecretsClient()\n",
    "            github_pat = user_secrets.get_secret(\"GITHUB_PAT\")\n",
    "\n",
    "            os.chdir(\"/kaggle/working\")\n",
    "            os.system(\n",
    "                f\"git clone -b class-imbalance https://{github_pat}@github.com/lfaoliveira/STROKE_PREDICTION.git\"\n",
    "            )\n",
    "            os.chdir(PATH_DATASET)\n",
    "\n",
    "        elif os.environ[\"AMBIENTE\"] == \"LOCAL\":\n",
    "            os.system(\"git pull origin main\")\n",
    "\n",
    "        # Install dependencies\n",
    "        os.chdir(PATH_DATASET)\n",
    "        os.system(\"uv pip install --requirements pyproject.toml --system\")\n",
    "\n",
    "        if os.environ[\"AMBIENTE\"] == \"KAGGLE\":\n",
    "            os.system(\n",
    "                \"uv pip install --upgrade --force-reinstall --no-cache-dir scipy numpy matplotlib protobuf tensorboard\"\n",
    "            )\n",
    "\n",
    "        # Mark installation as complete\n",
    "        INSTALL_MARKER.touch()\n",
    "        print(\"Installation completed\")\n",
    "    else:\n",
    "        print(\"Installation already completed, skipping...\")\n",
    "\n",
    "    os.chdir(PATH_CODE)\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except Exception:\n",
    "    print(\"FALHA AO INICIAR NOTEBOOK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226e767",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcesser.dataset import StrokeDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Load data\n",
    "# =========================\n",
    "df = StrokeDataset().original_df.copy()\n",
    "\n",
    "# =========================\n",
    "# 1. Dataset overview\n",
    "# =========================\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\\n\", df.isna().sum())\n",
    "\n",
    "# =========================\n",
    "# 2. Target distribution\n",
    "# =========================\n",
    "stroke_dist = df[\"stroke\"].value_counts(normalize=True) * 100\n",
    "print(\"\\nStroke distribution (%):\\n\", stroke_dist)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# =========================\n",
    "# 1. Stroke distribution\n",
    "# =========================\n",
    "df[\"stroke\"].value_counts().sort_index().plot(kind=\"bar\", ax=axes[0])\n",
    "axes[0].set_title(\"Stroke Distribution (Imbalanced)\")\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels([\"No Stroke\", \"Stroke\"], rotation=0)\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_yticks([i for i in range(0, 4501, 500)])\n",
    "# =========================\n",
    "# 2. Age vs Stroke\n",
    "# =========================\n",
    "df.boxplot(column=\"age\", by=\"stroke\", ax=axes[1])\n",
    "axes[1].set_title(\"Age by Stroke\")\n",
    "axes[1].set_xlabel(\"Stroke\")\n",
    "axes[1].set_ylabel(\"Age\")\n",
    "\n",
    "# =========================\n",
    "# 3. Glucose vs Stroke\n",
    "# =========================\n",
    "df.boxplot(column=\"avg_glucose_level\", by=\"stroke\", ax=axes[2])\n",
    "axes[2].set_title(\"Avg Glucose by Stroke\")\n",
    "axes[2].set_xlabel(\"Stroke\")\n",
    "axes[2].set_ylabel(\"Glucose Level\")\n",
    "\n",
    "# =========================\n",
    "# 4. BMI vs Stroke\n",
    "# =========================\n",
    "df.boxplot(column=\"bmi\", by=\"stroke\", ax=axes[3])\n",
    "axes[3].set_title(\"BMI by Stroke\")\n",
    "axes[3].set_xlabel(\"Stroke\")\n",
    "axes[3].set_ylabel(\"BMI\")\n",
    "\n",
    "# =========================\n",
    "# 5. Hypertension\n",
    "# =========================\n",
    "pd.crosstab(df[\"hypertension\"], df[\"stroke\"], normalize=\"index\").mul(100).plot(\n",
    "    kind=\"bar\", ax=axes[4], rot=0\n",
    ")\n",
    "axes[4].set_title(\"Stroke Rate by Hypertension\")\n",
    "axes[4].set_ylabel(\"Percentage (%)\")\n",
    "axes[4].legend([\"No Stroke\", \"Stroke\"])\n",
    "\n",
    "# =========================\n",
    "# 6. Heart disease\n",
    "# =========================\n",
    "pd.crosstab(df[\"heart_disease\"], df[\"stroke\"], normalize=\"index\").mul(100).plot(\n",
    "    kind=\"bar\", ax=axes[5], rot=0\n",
    ")\n",
    "axes[5].set_title(\"Stroke Rate by Heart Disease\")\n",
    "axes[5].set_ylabel(\"Percentage (%)\")\n",
    "axes[5].legend([\"No Stroke\", \"Stroke\"])\n",
    "\n",
    "# =========================\n",
    "# 7. Smoking status\n",
    "# =========================\n",
    "pd.crosstab(df[\"smoking_status\"], df[\"stroke\"], normalize=\"index\").mul(100).sort_values(\n",
    "    by=1\n",
    ").plot(kind=\"barh\", ax=axes[6])\n",
    "axes[6].set_title(\"Stroke Rate by Smoking Status\")\n",
    "axes[6].set_xlabel(\"Percentage (%)\")\n",
    "axes[6].legend([\"No Stroke\", \"Stroke\"])\n",
    "\n",
    "# =========================\n",
    "# 8. Work type\n",
    "# =========================\n",
    "pd.crosstab(df[\"work_type\"], df[\"stroke\"], normalize=\"index\").mul(100).sort_values(\n",
    "    by=1\n",
    ").plot(kind=\"bar\", ax=axes[7], rot=30)\n",
    "axes[7].set_title(\"Stroke Rate by Work Type\")\n",
    "axes[7].set_ylabel(\"Percentage (%)\")\n",
    "axes[7].legend([\"No Stroke\", \"Stroke\"])\n",
    "\n",
    "# =========================\n",
    "# 9. Empty / summary slot\n",
    "# =========================\n",
    "axes[8].axis(\"off\")\n",
    "axes[8].set_title(\"EDA Summary Slot\")\n",
    "\n",
    "plt.suptitle(\"Stroke Dataset – Exploratory Data Analysis\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c57917",
   "metadata": {},
   "source": [
    "## Training with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from typing import Callable, Literal\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "\n",
    "from Models.mlp import MLP, MLPSearchSpace\n",
    "from lightning import Callback, seed_everything, Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "import mlflow\n",
    "from mlflow.pytorch import autolog\n",
    "from DataProcesser.datamodule import StrokeDataModule\n",
    "import optuna\n",
    "from Models.kan import KANSearchSpace, MyKan\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Callbacks\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class EpochProgressCallback(Callback):\n",
    "    \"\"\"Lightning Callback that updates a tqdm progress bar every epoch.\"\"\"\n",
    "\n",
    "    def __init__(self, pbar_epoch: tqdm, max_epochs: int):\n",
    "        super().__init__()\n",
    "        self.pbar_epoch = pbar_epoch\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.pbar_epoch.reset(total=self.max_epochs)\n",
    "        self.pbar_epoch.set_description(\"Epochs\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        metrics = trainer.callback_metrics\n",
    "        train_loss = metrics.get(\"train_loss\")\n",
    "        val_loss = metrics.get(\"val_loss\")\n",
    "        postfix = {}\n",
    "        if train_loss is not None:\n",
    "            postfix[\"train_loss\"] = f\"{train_loss.item():.4f}\"\n",
    "        if val_loss is not None:\n",
    "            postfix[\"val_loss\"] = f\"{val_loss.item():.4f}\"\n",
    "        postfix[\"epoch\"] = trainer.current_epoch + 1\n",
    "        self.pbar_epoch.set_postfix(postfix)\n",
    "        self.pbar_epoch.update(1)\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        self.pbar_epoch.refresh()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Utilities\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def hard_delete_optuna(\n",
    "    code_path: Path = PATH_CODE,\n",
    "    output_path: Path = PATH_OUTPUT_DIR,\n",
    "):\n",
    "    import shutil\n",
    "\n",
    "    deleted_items = []\n",
    "    # Full cleanup - remove everything\n",
    "    db_path = code_path / \"mlflow.db\"\n",
    "    if db_path.exists():\n",
    "        os.remove(db_path)\n",
    "        deleted_items.append(f\"Database: {db_path}\")\n",
    "\n",
    "    mlruns_path = code_path / \"mlruns\"\n",
    "    if mlruns_path.exists():\n",
    "        shutil.rmtree(mlruns_path)\n",
    "        deleted_items.append(f\"MLruns folder: {mlruns_path}\")\n",
    "\n",
    "    artifacts_dir = output_path / \"artifacts\"\n",
    "    if artifacts_dir.exists():\n",
    "        shutil.rmtree(artifacts_dir)\n",
    "        deleted_items.append(f\"Artifacts: {artifacts_dir}\")\n",
    "\n",
    "    best_runs_csv = output_path / \"best_optuna_runs.csv\"\n",
    "    if best_runs_csv.exists():\n",
    "        os.remove(best_runs_csv)\n",
    "        deleted_items.append(f\"Best runs CSV: {best_runs_csv}\")\n",
    "\n",
    "\n",
    "def clear_optuna_bad_trainings(\n",
    "    output_path: Path = PATH_OUTPUT_DIR,\n",
    "    preserve_optuna: bool = True,\n",
    "    verbose: bool = True,\n",
    "    best_runs: list[str] | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Clears MLflow and training artifacts.\n",
    "\n",
    "    Args:\n",
    "        code_path: Path to the code directory containing mlflow.db\n",
    "        output_path: Path to the outputs directory\n",
    "        preserve_optuna: If True, keeps only essential Optuna results (mlflow.db and outputs folder).\n",
    "                        If False, performs full cleanup including MLflow database.\n",
    "        verbose: Whether to print deletion messages\n",
    "\n",
    "    When preserve_optuna=True (safe for post-Optuna cleanup):\n",
    "        - Keeps: mlflow.db (contains all trial data)\n",
    "        - Keeps: mlruns folder\n",
    "        - Keeps: outputs folder structure and best_optuna_runs.csv\n",
    "        - Keeps: Best run's artifacts for each model\n",
    "        - Deletes: Trial CSV files in outputs/artifacts/ (except best runs)\n",
    "\n",
    "    When preserve_optuna=False (full cleanup):\n",
    "        - Removes everything: mlflow.db, mlruns/, outputs/artifacts/, best_optuna_runs.csv\n",
    "    \"\"\"\n",
    "\n",
    "    assert best_runs is not None\n",
    "    deleted_items = []\n",
    "\n",
    "    if preserve_optuna:\n",
    "        # Delete trial CSV files in artifacts directory, but keep best run artifacts\n",
    "        artifacts_dir = output_path / \"artifacts\"\n",
    "        if artifacts_dir.exists():\n",
    "            csv_files = list(artifacts_dir.glob(\"test_results_*.csv\"))\n",
    "            for csv_file in csv_files:\n",
    "                # Extract run_id from filename: test_results_<run_id>.csv\n",
    "                run_id = csv_file.stem.replace(\"test_results_\", \"\")\n",
    "                if run_id not in best_runs:\n",
    "                    os.remove(csv_file)\n",
    "                    deleted_items.append(f\"Trial artifact: {csv_file.name}\")\n",
    "                elif verbose:\n",
    "                    print(f\"  ↷ Keeping best run artifact: {csv_file.name}\")\n",
    "\n",
    "    if verbose:\n",
    "        mode = (\n",
    "            \"preserving best results (mlflow.db + outputs)\"\n",
    "            if preserve_optuna\n",
    "            else \"full cleanup\"\n",
    "        )\n",
    "        print(f\"Running {mode}...\")\n",
    "        if deleted_items:\n",
    "            print(\"Successfully deleted:\")\n",
    "            for item in deleted_items:\n",
    "                print(f\"  {item}\")\n",
    "        else:\n",
    "            print(\"No training artifacts found to delete.\")\n",
    "    else:\n",
    "        print(\"Running Cleanup...\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def supress_warnings():\n",
    "    logging.getLogger(\"mlflow.utils.requirements_utils\").setLevel(logging.ERROR)\n",
    "    logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "    logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.ERROR)\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "def model_choice(\n",
    "    choice: str,\n",
    "    input_dims: int,\n",
    "    trial: optuna.trial.Trial,\n",
    "    n_classes: int,\n",
    "    recall_factor: list[float],\n",
    "):\n",
    "    if choice == \"MLP\":\n",
    "        search_space = MLPSearchSpace()\n",
    "        suggested_hparams = search_space.suggest_optuna(trial)\n",
    "        model = MLP(\n",
    "            input_dims,\n",
    "            n_classes,\n",
    "            recall_factor=recall_factor,\n",
    "            hyperparameters=suggested_hparams,\n",
    "        )\n",
    "        return model, suggested_hparams, search_space.Keys\n",
    "    elif choice == \"KAN\":\n",
    "        search_space = KANSearchSpace()\n",
    "        suggested_hparams = search_space.suggest_optuna(trial)\n",
    "        model = MyKan(\n",
    "            input_dims,\n",
    "            n_classes,\n",
    "            recall_factor=recall_factor,\n",
    "            hyperparameters=suggested_hparams,\n",
    "        )\n",
    "        return model, suggested_hparams, search_space.Keys\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model choice: {choice}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Extracted helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _build_trainer(\n",
    "    gpu: bool,\n",
    "    epochs: int,\n",
    "    patience: int,\n",
    "    mlflow_logger: MLFlowLogger,\n",
    "    early_stop: bool = True,\n",
    "    extra_callbacks: list[Callback] | None = None,\n",
    ") -> Trainer:\n",
    "    callbacks: list[Callback] = []\n",
    "    if early_stop:\n",
    "        callbacks.append(EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\"))\n",
    "    if extra_callbacks:\n",
    "        callbacks.extend(extra_callbacks)\n",
    "    return Trainer(\n",
    "        max_epochs=epochs,\n",
    "        devices=1,\n",
    "        accelerator=\"gpu\" if gpu else \"cpu\",\n",
    "        num_nodes=1,\n",
    "        logger=mlflow_logger,\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=callbacks if callbacks else None,\n",
    "    )\n",
    "\n",
    "\n",
    "def _test_and_log_artifacts(\n",
    "    model,\n",
    "    datamodule: StrokeDataModule,\n",
    "    batch_size: int,\n",
    "    run: mlflow.ActiveRun,\n",
    "    artifact_path: Path,\n",
    ") -> None:\n",
    "    \"\"\"Run the test step, log metrics and save the predictions CSV as an MLflow artifact.\"\"\"\n",
    "    import shutil\n",
    "\n",
    "    test_df = datamodule.dataset.original_df.copy()\n",
    "    test_df[\"pred\"] = None\n",
    "    test_df[\"error\"] = None\n",
    "\n",
    "    _, test_dataset = datamodule.test_dataloader(batch_size)\n",
    "    return_dict = model.test_step(test_dataset=test_dataset, output_df=test_df)\n",
    "    test_df = return_dict[\"output_df\"]\n",
    "\n",
    "    test_results = model.test_metrics.compute()\n",
    "    mlflow.log_metrics(\n",
    "        {f\"test_{k}\": float(v) for k, v in test_results.items() if v.numel() == 1}\n",
    "    )\n",
    "    model.test_metrics.reset()\n",
    "\n",
    "    path_test_csv = artifact_path / f\"test_results_{run.info.run_id}.csv\"\n",
    "    if path_test_csv.exists() and path_test_csv.is_dir():\n",
    "        shutil.rmtree(path_test_csv)\n",
    "\n",
    "    test_df.to_csv(path_test_csv)\n",
    "    assert path_test_csv.exists(), f\"CSV not found at {path_test_csv}\"\n",
    "    mlflow.log_artifact(str(path_test_csv))\n",
    "\n",
    "\n",
    "def _tag_best_run(exp_name: str, prefix: str) -> str :\n",
    "    \"\"\"Find the trial with the lowest val_loss and attach a human-readable name tag. Also appends choice and best run_id to csv\"\"\"\n",
    "    experiment = mlflow.get_experiment_by_name(exp_name)\n",
    "    if not experiment:\n",
    "        return \"\"\n",
    "\n",
    "    output_filename = os.environ[\"OPTUNA_BEST_RUN_CSV\"]\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        mlflow.search_runs(\n",
    "            experiment_ids=[experiment.experiment_id],\n",
    "            order_by=[\"metrics.val_loss ASC\"],\n",
    "        )\n",
    "    ).dropna(subset=[\"metrics.val_loss\"])\n",
    "\n",
    "    if runs_df.empty:\n",
    "        raise RuntimeError(f\"No runs with val_loss found for experiment '{exp_name}'\")\n",
    "\n",
    "    best_run_id = str(runs_df.iloc[0].run_id)\n",
    "    choice = exp_name.split(\"_\")[0]\n",
    "    print(f\"BEST ID: {best_run_id} for {choice} model\")\n",
    "    mlflow.MlflowClient().set_tag(best_run_id, \"mlflow.runName\", f\"{prefix}_{choice}\")\n",
    "    with open(output_filename, \"a\") as f:\n",
    "        f.write(f\"{choice},{best_run_id}\\n\")\n",
    "\n",
    "    return best_run_id\n",
    "\n",
    "\n",
    "def _check_tuning_already_complete(choice: str) -> str | None:\n",
    "    \"\"\"Check if tuning for this model already completed by looking at the best runs CSV.\n",
    "    Returns the best_run_id if found, None otherwise.\"\"\"\n",
    "    csv_path = os.environ.get(\"OPTUNA_BEST_RUN_CSV\", \"\")\n",
    "    if not csv_path or not Path(csv_path).exists():\n",
    "        return None\n",
    "    df = pd.read_csv(csv_path, header=None, names=[\"model\", \"run_id\"])\n",
    "    matching = df[df[\"model\"] == choice]\n",
    "    if matching.empty:\n",
    "        return None\n",
    "    return str(matching.iloc[0][\"run_id\"])\n",
    "\n",
    "\n",
    "def _run_optuna_study(\n",
    "    objective: Callable,\n",
    "    n_trials: int,\n",
    "    study_name: str,\n",
    "    optuna_storage: str,\n",
    "    parent_run: mlflow.ActiveRun,\n",
    ") -> optuna.Study:\n",
    "    \"\"\"Create or resume the Optuna study, optimise, and log summary metrics to the parent run.\"\"\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=optuna_storage,\n",
    "        study_name=study_name,\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    n_completed = len(completed_trials)\n",
    "    remaining = max(0, n_trials - n_completed)\n",
    "\n",
    "    if n_completed > 0:\n",
    "        print(f\"Resuming study '{study_name}': {n_completed}/{n_trials} trials already completed, {remaining} remaining.\")\n",
    "    \n",
    "    if remaining > 0:\n",
    "        study.optimize(objective, n_trials=remaining, gc_after_trial=True)\n",
    "    else:\n",
    "        print(f\"Study '{study_name}' already has {n_completed} completed trials (target: {n_trials}). Skipping optimization.\")\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {\"best_\" + k: v for k, v in study.best_trial.params.items()},\n",
    "        run_id=parent_run.info.run_id,\n",
    "    )\n",
    "    mlflow.log_metric(\n",
    "        \"best_val_loss\",\n",
    "        study.best_trial.value or float(\"inf\"),\n",
    "        run_id=parent_run.info.run_id,\n",
    "    )\n",
    "    mlflow.log_params(\n",
    "        {\"best_trial_id\": study.best_trial.user_attrs.get(\"run_id\")},\n",
    "        run_id=parent_run.info.run_id,\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "    print(\"Best validation loss:\", study.best_trial.value)\n",
    "    return study\n",
    "\n",
    "\n",
    "def _make_objective(\n",
    "    choice: str,\n",
    "    input_dims: int,\n",
    "    n_classes: int,\n",
    "    datamodule: StrokeDataModule,\n",
    "    exp_name: str,\n",
    "    mlf_track_uri: str,\n",
    "    gpu: bool,\n",
    "    epochs: int,\n",
    "    patience: int,\n",
    "    artifact_path: Path,\n",
    "    pbar: tqdm,\n",
    "    pbar_epoch: tqdm,\n",
    "    log_models: bool,\n",
    "):\n",
    "    \"\"\"Factory method - returns the Optuna objective closure with all context captured.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        model, hyperparameters, keys = model_choice(\n",
    "            choice, input_dims, trial, n_classes, datamodule.class_weights\n",
    "        )\n",
    "        batch_size = hyperparameters[keys.BATCH_SIZE]\n",
    "\n",
    "        train_loader = datamodule.train_dataloader(batch_size)\n",
    "        val_loader = datamodule.val_dataloader(batch_size)\n",
    "        _ = model(model.example_input_array)\n",
    "\n",
    "        epoch_cb = EpochProgressCallback(pbar_epoch, epochs)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True) as run:\n",
    "            mlflow_logger = MLFlowLogger(\n",
    "                experiment_name=exp_name,\n",
    "                tracking_uri=mlf_track_uri,\n",
    "                log_model=log_models,\n",
    "                run_id=run.info.run_id,\n",
    "            )\n",
    "            trainer = _build_trainer(gpu, epochs, patience, mlflow_logger, extra_callbacks=[epoch_cb])\n",
    "            trainer.fit(\n",
    "                model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "            )\n",
    "            mlflow.log_params(dict(model.hparams))\n",
    "            val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "            _test_and_log_artifacts(model, datamodule, batch_size, run, artifact_path)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\"val_loss\": f\"{val_loss:.4f}\", \"trial\": trial.number})\n",
    "        return val_loss\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def main(CHOICE: str, MLF_TRACK_URI: str):\n",
    "    import pickle\n",
    "\n",
    "    seed_everything(42)\n",
    "    supress_warnings()\n",
    "\n",
    "    # Check if tuning for this model already completed\n",
    "    existing_best = _check_tuning_already_complete(CHOICE)\n",
    "    if existing_best:\n",
    "        print(f\"Tuning for {CHOICE} already complete (best_run_id={existing_best}). Skipping.\")\n",
    "        return existing_best\n",
    "\n",
    "    # Set OPTUNA_LOG_MODELS=true to save model weights for every trial (WARNING: increases disk usage significantly)\n",
    "    LOG_MODELS = False\n",
    "\n",
    "    GPU = os.environ[\"AMBIENTE\"] in [\"KAGGLE\", \"COLAB\"]\n",
    "    WORKERS = os.cpu_count() or 1\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 40\n",
    "    TRIALS = 20\n",
    "    PATIENCE = 25\n",
    "    ARTIFACT_PATH = PATH_OUTPUT_DIR / \"artifacts\"\n",
    "    os.makedirs(ARTIFACT_PATH, exist_ok=True)\n",
    "\n",
    "    EXP_NAME = f\"{CHOICE}_TUNING\"\n",
    "    mlflow.set_tracking_uri(MLF_TRACK_URI)\n",
    "    mlflow.set_experiment(EXP_NAME)\n",
    "    autolog(log_models=LOG_MODELS, checkpoint=LOG_MODELS, exclusive=False)\n",
    "\n",
    "    datamodule = StrokeDataModule(BATCH_SIZE, WORKERS)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup(\"fit\")\n",
    "    INPUT_DIMS = datamodule.input_dims or -1\n",
    "    assert INPUT_DIMS > 0\n",
    "\n",
    "    # Check how many trials already exist in the Optuna DB to set progress bar correctly\n",
    "    optuna_storage = \"sqlite:///optuna.db\"\n",
    "    study_name = f\"{CHOICE}_TUNING\"\n",
    "    n_already_done = 0\n",
    "    try:\n",
    "        existing_study = optuna.load_study(study_name=study_name, storage=optuna_storage)\n",
    "        n_already_done = len([t for t in existing_study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "        del existing_study\n",
    "    except KeyError:\n",
    "        pass  # Study doesn't exist yet\n",
    "\n",
    "    remaining = max(0, TRIALS - n_already_done)\n",
    "    if remaining == 0:\n",
    "        print(f\"All {TRIALS} trials already completed for {CHOICE}. Tagging best run.\")\n",
    "    else:\n",
    "        if n_already_done > 0:\n",
    "            print(f\"Resuming {CHOICE}: {n_already_done}/{TRIALS} trials done, {remaining} remaining.\")\n",
    "\n",
    "    pbar = tqdm(\n",
    "        total=remaining, desc=f\"({CHOICE}) trials\", position=0, leave=True, colour=\"green\"\n",
    "    )\n",
    "    pbar_epoch = tqdm(\n",
    "        total=EPOCHS, desc=\"Epochs\", position=1, leave=False, colour=\"blue\"\n",
    "    )\n",
    "\n",
    "    objective = _make_objective(\n",
    "        choice=CHOICE,\n",
    "        input_dims=INPUT_DIMS,\n",
    "        n_classes=2,\n",
    "        datamodule=datamodule,\n",
    "        exp_name=EXP_NAME,\n",
    "        mlf_track_uri=MLF_TRACK_URI,\n",
    "        gpu=GPU,\n",
    "        epochs=EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        artifact_path=ARTIFACT_PATH,\n",
    "        pbar=pbar,\n",
    "        pbar_epoch=pbar_epoch,\n",
    "        log_models=LOG_MODELS,\n",
    "    )\n",
    "\n",
    "    best_run_id = None\n",
    "    with mlflow.start_run(run_name=None) as parent_run:\n",
    "        _run_optuna_study(objective, TRIALS, study_name, optuna_storage, parent_run)\n",
    "        pbar.close()\n",
    "        pbar_epoch.close()\n",
    "\n",
    "        best_run_id = _tag_best_run(EXP_NAME, os.environ[\"OPTUNA_BEST_RUN_PREFIX\"])\n",
    "        \n",
    "    assert best_run_id is not None\n",
    "\n",
    "    return best_run_id\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\", \"RNDFOREST\", \"LIQUIDNN\"]\n",
    "        models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "        MLF_TRACK_URI = f\"sqlite:///{PATH_CODE}/mlflow.db\"\n",
    "\n",
    "        os.environ[\"OPTUNA\"] = \"True\"\n",
    "        os.environ[\"OPTUNA_BEST_RUN_PREFIX\"] = \"best_run\"\n",
    "        os.environ[\"OPTUNA_LOG_MODELS\"] = \"false\"  # Set to \"true\" to save model weights per trial\n",
    "        best_runs_csv = PATH_OUTPUT_DIR / \"best_optuna_runs.csv\"\n",
    "        os.environ[\"OPTUNA_BEST_RUN_CSV\"] = str(best_runs_csv)\n",
    "\n",
    "        supress_warnings()\n",
    "        best_runs = []\n",
    "        for choice in models:\n",
    "            best_run_id = main(choice, MLF_TRACK_URI)\n",
    "            best_runs.append(best_run_id)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        clear_optuna_bad_trainings(best_runs=best_runs)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"PREMATURELY INTERRUPTING...\\n\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bea8bf",
   "metadata": {},
   "source": [
    "## Optuna + Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba95c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from typing import Callable, Literal\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "\n",
    "from Models.mlp import MLP, MLPSearchSpace\n",
    "from lightning import Callback, seed_everything, Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "import mlflow\n",
    "from mlflow.pytorch import autolog\n",
    "from DataProcesser.datamodule import StrokeDataModule\n",
    "import optuna\n",
    "from Models.kan import KANSearchSpace, MyKan\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Callbacks\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class EpochProgressCallback(Callback):\n",
    "    \"\"\"Lightning Callback that updates a tqdm progress bar every epoch.\"\"\"\n",
    "\n",
    "    def __init__(self, pbar_epoch: tqdm, max_epochs: int):\n",
    "        super().__init__()\n",
    "        self.pbar_epoch = pbar_epoch\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.pbar_epoch.reset(total=self.max_epochs)\n",
    "        self.pbar_epoch.set_description(\"Epochs\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        metrics = trainer.callback_metrics\n",
    "        train_loss = metrics.get(\"train_loss\")\n",
    "        val_loss = metrics.get(\"val_loss\")\n",
    "        postfix = {}\n",
    "        if train_loss is not None:\n",
    "            postfix[\"train_loss\"] = f\"{train_loss.item():.4f}\"\n",
    "        if val_loss is not None:\n",
    "            postfix[\"val_loss\"] = f\"{val_loss.item():.4f}\"\n",
    "        postfix[\"epoch\"] = trainer.current_epoch + 1\n",
    "        self.pbar_epoch.set_postfix(postfix)\n",
    "        self.pbar_epoch.update(1)\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        self.pbar_epoch.refresh()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Utilities\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def hard_delete_optuna(\n",
    "    code_path: Path = PATH_CODE,\n",
    "    output_path: Path = PATH_OUTPUT_DIR,\n",
    "):\n",
    "    import shutil\n",
    "\n",
    "    deleted_items = []\n",
    "    # Full cleanup - remove everything\n",
    "    db_path = code_path / \"mlflow.db\"\n",
    "    if db_path.exists():\n",
    "        os.remove(db_path)\n",
    "        deleted_items.append(f\"Database: {db_path}\")\n",
    "\n",
    "    mlruns_path = code_path / \"mlruns\"\n",
    "    if mlruns_path.exists():\n",
    "        shutil.rmtree(mlruns_path)\n",
    "        deleted_items.append(f\"MLruns folder: {mlruns_path}\")\n",
    "\n",
    "    artifacts_dir = output_path / \"artifacts\"\n",
    "    if artifacts_dir.exists():\n",
    "        shutil.rmtree(artifacts_dir)\n",
    "        deleted_items.append(f\"Artifacts: {artifacts_dir}\")\n",
    "\n",
    "    best_runs_csv = output_path / \"best_optuna_runs.csv\"\n",
    "    if best_runs_csv.exists():\n",
    "        os.remove(best_runs_csv)\n",
    "        deleted_items.append(f\"Best runs CSV: {best_runs_csv}\")\n",
    "\n",
    "\n",
    "def clear_optuna_bad_trainings(\n",
    "    output_path: Path = PATH_OUTPUT_DIR,\n",
    "    preserve_optuna: bool = True,\n",
    "    verbose: bool = True,\n",
    "    best_runs: list[str] | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Clears MLflow and training artifacts.\n",
    "\n",
    "    Args:\n",
    "        code_path: Path to the code directory containing mlflow.db\n",
    "        output_path: Path to the outputs directory\n",
    "        preserve_optuna: If True, keeps only essential Optuna results (mlflow.db and outputs folder).\n",
    "                        If False, performs full cleanup including MLflow database.\n",
    "        verbose: Whether to print deletion messages\n",
    "\n",
    "    When preserve_optuna=True (safe for post-Optuna cleanup):\n",
    "        - Keeps: mlflow.db (contains all trial data)\n",
    "        - Keeps: mlruns folder\n",
    "        - Keeps: outputs folder structure and best_optuna_runs.csv\n",
    "        - Keeps: Best run's artifacts for each model\n",
    "        - Deletes: Trial CSV files in outputs/artifacts/ (except best runs)\n",
    "\n",
    "    When preserve_optuna=False (full cleanup):\n",
    "        - Removes everything: mlflow.db, mlruns/, outputs/artifacts/, best_optuna_runs.csv\n",
    "    \"\"\"\n",
    "\n",
    "    assert best_runs is not None\n",
    "    deleted_items = []\n",
    "\n",
    "    if preserve_optuna:\n",
    "        # Delete trial CSV files in artifacts directory, but keep best run artifacts\n",
    "        artifacts_dir = output_path / \"artifacts\"\n",
    "        if artifacts_dir.exists():\n",
    "            csv_files = list(artifacts_dir.glob(\"test_results_*.csv\"))\n",
    "            for csv_file in csv_files:\n",
    "                # Extract run_id from filename: test_results_<run_id>.csv\n",
    "                run_id = csv_file.stem.replace(\"test_results_\", \"\")\n",
    "                if run_id not in best_runs:\n",
    "                    os.remove(csv_file)\n",
    "                    deleted_items.append(f\"Trial artifact: {csv_file.name}\")\n",
    "                elif verbose:\n",
    "                    print(f\"  ↷ Keeping best run artifact: {csv_file.name}\")\n",
    "\n",
    "    if verbose:\n",
    "        mode = (\n",
    "            \"preserving best results (mlflow.db + outputs)\"\n",
    "            if preserve_optuna\n",
    "            else \"full cleanup\"\n",
    "        )\n",
    "        print(f\"Running {mode}...\")\n",
    "        if deleted_items:\n",
    "            print(\"Successfully deleted:\")\n",
    "            for item in deleted_items:\n",
    "                print(f\"  {item}\")\n",
    "        else:\n",
    "            print(\"No training artifacts found to delete.\")\n",
    "    else:\n",
    "        print(\"Running Cleanup...\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def supress_warnings():\n",
    "    logging.getLogger(\"mlflow.utils.requirements_utils\").setLevel(logging.ERROR)\n",
    "    logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "    logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.ERROR)\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "def model_choice(\n",
    "    choice: str,\n",
    "    input_dims: int,\n",
    "    trial: optuna.trial.Trial,\n",
    "    n_classes: int,\n",
    "    recall_factor: list[float],\n",
    "):\n",
    "    if choice == \"MLP\":\n",
    "        search_space = MLPSearchSpace()\n",
    "        suggested_hparams = search_space.suggest_optuna(trial)\n",
    "        model = MLP(\n",
    "            input_dims,\n",
    "            n_classes,\n",
    "            recall_factor=recall_factor,\n",
    "            hyperparameters=suggested_hparams,\n",
    "        )\n",
    "        return model, suggested_hparams, search_space.Keys\n",
    "    elif choice == \"KAN\":\n",
    "        search_space = KANSearchSpace()\n",
    "        suggested_hparams = search_space.suggest_optuna(trial)\n",
    "        model = MyKan(\n",
    "            input_dims,\n",
    "            n_classes,\n",
    "            recall_factor=recall_factor,\n",
    "            hyperparameters=suggested_hparams,\n",
    "        )\n",
    "        return model, suggested_hparams, search_space.Keys\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model choice: {choice}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Extracted helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _build_trainer(\n",
    "    gpu: bool,\n",
    "    epochs: int,\n",
    "    patience: int,\n",
    "    mlflow_logger: MLFlowLogger,\n",
    "    early_stop: bool = True,\n",
    "    extra_callbacks: list[Callback] | None = None,\n",
    ") -> Trainer:\n",
    "    callbacks: list[Callback] = []\n",
    "    if early_stop:\n",
    "        callbacks.append(EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\"))\n",
    "    if extra_callbacks:\n",
    "        callbacks.extend(extra_callbacks)\n",
    "    return Trainer(\n",
    "        max_epochs=epochs,\n",
    "        devices=1,\n",
    "        accelerator=\"gpu\" if gpu else \"cpu\",\n",
    "        num_nodes=1,\n",
    "        logger=mlflow_logger,\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=callbacks if callbacks else None,\n",
    "    )\n",
    "\n",
    "\n",
    "def _test_and_log_artifacts(\n",
    "    model,\n",
    "    datamodule: StrokeDataModule,\n",
    "    batch_size: int,\n",
    "    run: mlflow.ActiveRun,\n",
    "    artifact_path: Path,\n",
    ") -> None:\n",
    "    \"\"\"Run the test step, log metrics and save the predictions CSV as an MLflow artifact.\"\"\"\n",
    "    import shutil\n",
    "\n",
    "    test_df = datamodule.dataset.original_df.copy()\n",
    "    test_df[\"pred\"] = None\n",
    "    test_df[\"error\"] = None\n",
    "\n",
    "    _, test_dataset = datamodule.test_dataloader(batch_size)\n",
    "    return_dict = model.test_step(test_dataset=test_dataset, output_df=test_df)\n",
    "    test_df = return_dict[\"output_df\"]\n",
    "\n",
    "    test_results = model.test_metrics.compute()\n",
    "    mlflow.log_metrics(\n",
    "        {f\"test_{k}\": float(v) for k, v in test_results.items() if v.numel() == 1}\n",
    "    )\n",
    "    model.test_metrics.reset()\n",
    "\n",
    "    path_test_csv = artifact_path / f\"test_results_{run.info.run_id}.csv\"\n",
    "    if path_test_csv.exists() and path_test_csv.is_dir():\n",
    "        shutil.rmtree(path_test_csv)\n",
    "\n",
    "    test_df.to_csv(path_test_csv)\n",
    "    assert path_test_csv.exists(), f\"CSV not found at {path_test_csv}\"\n",
    "    mlflow.log_artifact(str(path_test_csv))\n",
    "\n",
    "\n",
    "def _tag_best_run(exp_name: str, prefix: str) -> str :\n",
    "    \"\"\"Find the trial with the lowest val_loss and attach a human-readable name tag. Also appends choice and best run_id to csv\"\"\"\n",
    "    experiment = mlflow.get_experiment_by_name(exp_name)\n",
    "    if not experiment:\n",
    "        return \"\"\n",
    "\n",
    "    output_filename = os.environ[\"OPTUNA_BEST_RUN_CSV\"]\n",
    "\n",
    "    runs_df = pd.DataFrame(\n",
    "        mlflow.search_runs(\n",
    "            experiment_ids=[experiment.experiment_id],\n",
    "            order_by=[\"metrics.val_loss ASC\"],\n",
    "        )\n",
    "    ).dropna(subset=[\"metrics.val_loss\"])\n",
    "\n",
    "    if runs_df.empty:\n",
    "        raise RuntimeError(f\"No runs with val_loss found for experiment '{exp_name}'\")\n",
    "\n",
    "    best_run_id = str(runs_df.iloc[0].run_id)\n",
    "    choice = exp_name.split(\"_\")[0]\n",
    "    print(f\"BEST ID: {best_run_id} for {choice} model\")\n",
    "    mlflow.MlflowClient().set_tag(best_run_id, \"mlflow.runName\", f\"{prefix}_{choice}\")\n",
    "    with open(output_filename, \"a\") as f:\n",
    "        f.write(f\"{choice},{best_run_id}\\n\")\n",
    "\n",
    "    return best_run_id\n",
    "\n",
    "\n",
    "def _check_tuning_already_complete(choice: str) -> str | None:\n",
    "    \"\"\"Check if tuning for this model already completed by looking at the best runs CSV.\n",
    "    Returns the best_run_id if found, None otherwise.\"\"\"\n",
    "    csv_path = os.environ.get(\"OPTUNA_BEST_RUN_CSV\", \"\")\n",
    "    if not csv_path or not Path(csv_path).exists():\n",
    "        return None\n",
    "    df = pd.read_csv(csv_path, header=None, names=[\"model\", \"run_id\"])\n",
    "    matching = df[df[\"model\"] == choice]\n",
    "    if matching.empty:\n",
    "        return None\n",
    "    return str(matching.iloc[0][\"run_id\"])\n",
    "\n",
    "\n",
    "def _run_optuna_study(\n",
    "    objective: Callable,\n",
    "    n_trials: int,\n",
    "    study_name: str,\n",
    "    optuna_storage: str,\n",
    "    parent_run: mlflow.ActiveRun,\n",
    ") -> optuna.Study:\n",
    "    \"\"\"Create or resume the Optuna study, optimise, and log summary metrics to the parent run.\"\"\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=optuna_storage,\n",
    "        study_name=study_name,\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    n_completed = len(completed_trials)\n",
    "    remaining = max(0, n_trials - n_completed)\n",
    "\n",
    "    if n_completed > 0:\n",
    "        print(f\"Resuming study '{study_name}': {n_completed}/{n_trials} trials already completed, {remaining} remaining.\")\n",
    "    \n",
    "    if remaining > 0:\n",
    "        study.optimize(objective, n_trials=remaining, gc_after_trial=True)\n",
    "    else:\n",
    "        print(f\"Study '{study_name}' already has {n_completed} completed trials (target: {n_trials}). Skipping optimization.\")\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {\"best_\" + k: v for k, v in study.best_trial.params.items()},\n",
    "        run_id=parent_run.info.run_id,\n",
    "    )\n",
    "    mlflow.log_metric(\n",
    "        \"best_val_loss\",\n",
    "        study.best_trial.value or float(\"inf\"),\n",
    "        run_id=parent_run.info.run_id,\n",
    "    )\n",
    "    mlflow.log_params(\n",
    "        {\"best_trial_id\": study.best_trial.user_attrs.get(\"run_id\")},\n",
    "        run_id=parent_run.info.run_id,\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "    print(\"Best validation loss:\", study.best_trial.value)\n",
    "    return study\n",
    "\n",
    "\n",
    "def _make_objective(\n",
    "    choice: str,\n",
    "    input_dims: int,\n",
    "    n_classes: int,\n",
    "    datamodule: StrokeDataModule,\n",
    "    exp_name: str,\n",
    "    mlf_track_uri: str,\n",
    "    gpu: bool,\n",
    "    epochs: int,\n",
    "    patience: int,\n",
    "    artifact_path: Path,\n",
    "    pbar: tqdm,\n",
    "    pbar_epoch: tqdm,\n",
    "    log_models: bool,\n",
    "):\n",
    "    \"\"\"Factory method - returns the Optuna objective closure with all context captured.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        model, hyperparameters, keys = model_choice(\n",
    "            choice, input_dims, trial, n_classes, datamodule.class_weights\n",
    "        )\n",
    "        batch_size = hyperparameters[keys.BATCH_SIZE]\n",
    "\n",
    "        train_loader = datamodule.train_dataloader(batch_size)\n",
    "        val_loader = datamodule.val_dataloader(batch_size)\n",
    "        _ = model(model.example_input_array)\n",
    "\n",
    "        epoch_cb = EpochProgressCallback(pbar_epoch, epochs)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True) as run:\n",
    "            mlflow_logger = MLFlowLogger(\n",
    "                experiment_name=exp_name,\n",
    "                tracking_uri=mlf_track_uri,\n",
    "                log_model=log_models,\n",
    "                run_id=run.info.run_id,\n",
    "            )\n",
    "            trainer = _build_trainer(gpu, epochs, patience, mlflow_logger, extra_callbacks=[epoch_cb])\n",
    "            trainer.fit(\n",
    "                model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "            )\n",
    "            mlflow.log_params(dict(model.hparams))\n",
    "            val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "            _test_and_log_artifacts(model, datamodule, batch_size, run, artifact_path)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\"val_loss\": f\"{val_loss:.4f}\", \"trial\": trial.number})\n",
    "        return val_loss\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def main(CHOICE: str, MLF_TRACK_URI: str):\n",
    "    import pickle\n",
    "\n",
    "    seed_everything(42)\n",
    "    supress_warnings()\n",
    "\n",
    "    # Check if tuning for this model already completed\n",
    "    existing_best = _check_tuning_already_complete(CHOICE)\n",
    "    if existing_best:\n",
    "        print(f\"Tuning for {CHOICE} already complete (best_run_id={existing_best}). Skipping.\")\n",
    "        return existing_best\n",
    "\n",
    "    # Set OPTUNA_LOG_MODELS=true to save model weights for every trial (WARNING: increases disk usage significantly)\n",
    "    LOG_MODELS = False\n",
    "\n",
    "    GPU = os.environ[\"AMBIENTE\"] in [\"KAGGLE\", \"COLAB\"]\n",
    "    WORKERS = os.cpu_count() or 1\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 40\n",
    "    TRIALS = 20\n",
    "    PATIENCE = 25\n",
    "    ARTIFACT_PATH = PATH_OUTPUT_DIR / \"artifacts\"\n",
    "    os.makedirs(ARTIFACT_PATH, exist_ok=True)\n",
    "\n",
    "    EXP_NAME = f\"{CHOICE}_TUNING\"\n",
    "    mlflow.set_tracking_uri(MLF_TRACK_URI)\n",
    "    mlflow.set_experiment(EXP_NAME)\n",
    "    autolog(log_models=LOG_MODELS, checkpoint=LOG_MODELS, exclusive=False)\n",
    "\n",
    "    datamodule = StrokeDataModule(BATCH_SIZE, WORKERS)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup(\"fit\")\n",
    "    INPUT_DIMS = datamodule.input_dims or -1\n",
    "    assert INPUT_DIMS > 0\n",
    "\n",
    "    # Check how many trials already exist in the Optuna DB to set progress bar correctly\n",
    "    optuna_storage = \"sqlite:///optuna.db\"\n",
    "    study_name = f\"{CHOICE}_TUNING\"\n",
    "    n_already_done = 0\n",
    "    try:\n",
    "        existing_study = optuna.load_study(study_name=study_name, storage=optuna_storage)\n",
    "        n_already_done = len([t for t in existing_study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "        del existing_study\n",
    "    except KeyError:\n",
    "        pass  # Study doesn't exist yet\n",
    "\n",
    "    remaining = max(0, TRIALS - n_already_done)\n",
    "    if remaining == 0:\n",
    "        print(f\"All {TRIALS} trials already completed for {CHOICE}. Tagging best run.\")\n",
    "    else:\n",
    "        if n_already_done > 0:\n",
    "            print(f\"Resuming {CHOICE}: {n_already_done}/{TRIALS} trials done, {remaining} remaining.\")\n",
    "\n",
    "    pbar = tqdm(\n",
    "        total=remaining, desc=f\"({CHOICE}) trials\", position=0, leave=True, colour=\"green\"\n",
    "    )\n",
    "    pbar_epoch = tqdm(\n",
    "        total=EPOCHS, desc=\"Epochs\", position=1, leave=False, colour=\"blue\"\n",
    "    )\n",
    "\n",
    "    objective = _make_objective(\n",
    "        choice=CHOICE,\n",
    "        input_dims=INPUT_DIMS,\n",
    "        n_classes=2,\n",
    "        datamodule=datamodule,\n",
    "        exp_name=EXP_NAME,\n",
    "        mlf_track_uri=MLF_TRACK_URI,\n",
    "        gpu=GPU,\n",
    "        epochs=EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        artifact_path=ARTIFACT_PATH,\n",
    "        pbar=pbar,\n",
    "        pbar_epoch=pbar_epoch,\n",
    "        log_models=LOG_MODELS,\n",
    "    )\n",
    "\n",
    "    best_run_id = None\n",
    "    with mlflow.start_run(run_name=None) as parent_run:\n",
    "        _run_optuna_study(objective, TRIALS, study_name, optuna_storage, parent_run)\n",
    "        pbar.close()\n",
    "        pbar_epoch.close()\n",
    "\n",
    "        best_run_id = _tag_best_run(EXP_NAME, os.environ[\"OPTUNA_BEST_RUN_PREFIX\"])\n",
    "        \n",
    "    assert best_run_id is not None\n",
    "\n",
    "    return best_run_id\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\", \"RNDFOREST\", \"LIQUIDNN\"]\n",
    "        models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "        MLF_TRACK_URI = f\"sqlite:///{PATH_CODE}/mlflow.db\"\n",
    "\n",
    "        os.environ[\"OPTUNA\"] = \"True\"\n",
    "        os.environ[\"OPTUNA_BEST_RUN_PREFIX\"] = \"best_run\"\n",
    "        os.environ[\"OPTUNA_LOG_MODELS\"] = \"false\"  # Set to \"true\" to save model weights per trial\n",
    "        best_runs_csv = PATH_OUTPUT_DIR / \"best_optuna_runs.csv\"\n",
    "        os.environ[\"OPTUNA_BEST_RUN_CSV\"] = str(best_runs_csv)\n",
    "\n",
    "        supress_warnings()\n",
    "        best_runs = []\n",
    "        for choice in models:\n",
    "            best_run_id = main(choice, MLF_TRACK_URI)\n",
    "            best_runs.append(best_run_id)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        clear_optuna_bad_trainings(best_runs=best_runs)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"PREMATURELY INTERRUPTING...\\n\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef61c38",
   "metadata": {},
   "source": [
    "## Normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222276af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Any, Literal\n",
    "import logging\n",
    "\n",
    "import gc\n",
    "import mlflow\n",
    "import torch\n",
    "from Models.mlp import MLP, MLPSearchSpace\n",
    "from Models.kan import MyKan, KANSearchSpace\n",
    "from lightning import seed_everything, Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from mlflow.pytorch import autolog\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from DataProcesser.datamodule import StrokeDataModule\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_best_hyperparameters_from_optuna(choice: str, mlf_track_uri: str) -> dict:\n",
    "    \"\"\"\n",
    "    Reads the best run ID from the CSV file saved during Optuna training,\n",
    "    fetches the run from MLflow, and returns the hyperparameters as a dict.\n",
    "    \n",
    "    Args:\n",
    "        choice: Model architecture name (e.g., \"MLP\", \"KAN\")\n",
    "        mlf_track_uri: MLflow tracking URI\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of hyperparameters from the best Optuna run (with string keys)\n",
    "    \"\"\"\n",
    "    \n",
    "    csv_path = os.environ.get(\"OPTUNA_BEST_RUN_CSV\", \"best_optuna_run.csv\")\n",
    "    if not csv_path or not Path(csv_path).exists():\n",
    "        raise FileNotFoundError(f\"Optuna best runs CSV not found at {csv_path}\")\n",
    "    \n",
    "    # Read CSV and find the row matching the current choice\n",
    "    df = pd.read_csv(csv_path, header=None, names=[\"model\", \"run_id\"])\n",
    "    matching_rows = df[df[\"model\"] == choice]\n",
    "    \n",
    "    if matching_rows.empty:\n",
    "        raise ValueError(f\"No best run found for model '{choice}' in {csv_path}\")\n",
    "    \n",
    "    best_run_id = matching_rows.iloc[0][\"run_id\"]\n",
    "    \n",
    "    # Fetch the run from MLflow\n",
    "    mlflow.set_tracking_uri(mlf_track_uri)\n",
    "    run = mlflow.get_run(best_run_id)\n",
    "    \n",
    "    # Extract parameters\n",
    "    hyperparameters = dict(run.data.params)\n",
    "    \n",
    "    # Convert numeric strings back to appropriate types\n",
    "    for key, value in hyperparameters.items():\n",
    "        try:\n",
    "            # Try integer conversion first\n",
    "            hyperparameters[key] = int(value)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                # Try float conversion\n",
    "                hyperparameters[key] = float(value)\n",
    "            except ValueError:\n",
    "                # Keep as string\n",
    "                pass\n",
    "    \n",
    "    print(f\"{choice} STORED HYPERPARMS: {hyperparameters}\\n\")\n",
    "    return hyperparameters\n",
    "\n",
    "\n",
    "def zip_res(\n",
    "    path_sqlite: str,\n",
    "    path_mlflow: Path,\n",
    "    outputs_path: Path,\n",
    "    filename: str,\n",
    "    dest_folder: Path | None = None,\n",
    "):\n",
    "    import shutil\n",
    "\n",
    "    path_sqlite_clean = path_sqlite.replace(\"sqlite:///\", \"\")\n",
    "    print(f\"CWD: {Path.cwd()}\\n\")\n",
    "    PATH_TEMP = Path.cwd() / \"ZIP_TEMP\"\n",
    "    shutil.rmtree(PATH_TEMP, ignore_errors=True)\n",
    "    PATH_TEMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    shutil.copy(path_sqlite_clean, PATH_TEMP / Path(path_sqlite_clean).name)\n",
    "    shutil.copytree(path_mlflow, PATH_TEMP / path_mlflow.name)\n",
    "    shutil.copytree(outputs_path, PATH_TEMP / outputs_path.name)\n",
    "\n",
    "    # Determine destination folder\n",
    "    if dest_folder is None:\n",
    "        dest_folder = Path.cwd()\n",
    "    else:\n",
    "        dest_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create zip file in destination folder\n",
    "    zip_path = dest_folder / filename.replace(\".zip\", \"\")\n",
    "    shutil.make_archive(str(zip_path), \"zip\", PATH_TEMP)\n",
    "    shutil.rmtree(PATH_TEMP)\n",
    "    print(f\"PATH ZIPFILE: {zip_path.with_suffix('.zip').resolve()}\")\n",
    "\n",
    "\n",
    "def supress_warnings():\n",
    "    # Suppress specific MLflow warnings\n",
    "    logging.getLogger(\"mlflow.utils.requirements_utils\").setLevel(logging.ERROR)\n",
    "    logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "\n",
    "    # Suppress PyTorch Lightning info messages\n",
    "    logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def model_choice(CHOICE, INPUT_DIMS, N_CLASSES, recall_factor: list[float], optuna_hyperparams: dict[str, float|int] = {}):\n",
    "    if CHOICE == \"MLP\":\n",
    "        search_space = MLPSearchSpace()\n",
    "\n",
    "        keys = search_space.Keys\n",
    "        hyperparams = {\n",
    "            keys.BATCH_SIZE: 32,\n",
    "            keys.HIDDEN_DIMS: 512,\n",
    "            keys.LR: 2e-7,\n",
    "            keys.WEIGHT_DECAY: 1e-5,\n",
    "            keys.BETA0: 0.99,\n",
    "            keys.BETA1: 0.999,\n",
    "            keys.N_LAYERS: 80,\n",
    "        }\n",
    "        \n",
    "        # Map optuna hyperparams (string keys) to Keys enum\n",
    "        if optuna_hyperparams:\n",
    "            mapped_hyperparams = {}\n",
    "            for key_enum, default_value in hyperparams.items():\n",
    "                # Get the string representation of the enum key\n",
    "                key_str = key_enum.value\n",
    "                if key_str in optuna_hyperparams:\n",
    "                    mapped_hyperparams[key_enum] = optuna_hyperparams[key_str]\n",
    "                else:\n",
    "                    mapped_hyperparams[key_enum] = default_value\n",
    "            hyperparams = mapped_hyperparams\n",
    "        \n",
    "        print(f\"MLP HYPERPARAMS: {hyperparams}\")\n",
    "        suggested_hparams = search_space.suggest(hyperparams)\n",
    "        model = MLP(\n",
    "            INPUT_DIMS,\n",
    "            N_CLASSES,\n",
    "            recall_factor=recall_factor,\n",
    "            hyperparameters=suggested_hparams,\n",
    "        )\n",
    "    elif CHOICE == \"KAN\":\n",
    "        search_space = KANSearchSpace()\n",
    "        keys = search_space.Keys\n",
    "        hyperparams = {\n",
    "            keys.BATCH_SIZE: 32,\n",
    "            keys.HIDDEN_DIMS: 100,\n",
    "            keys.LR: 2e-7,\n",
    "            keys.WEIGHT_DECAY: 1e-5,\n",
    "            keys.BETA0: 0.99,\n",
    "            keys.BETA1: 0.999,\n",
    "            keys.GRID: 184,\n",
    "            keys.SPLINE_POL_ORDER: 4,\n",
    "        }\n",
    "        \n",
    "        # Map optuna hyperparams (string keys) to Keys enum\n",
    "        if optuna_hyperparams:\n",
    "            mapped_hyperparams = {}\n",
    "            for key_enum, default_value in hyperparams.items():\n",
    "                # Get the string representation of the enum key\n",
    "                key_str = key_enum.value\n",
    "                if key_str in optuna_hyperparams:\n",
    "                    mapped_hyperparams[key_enum] = optuna_hyperparams[key_str]\n",
    "                else:\n",
    "                    mapped_hyperparams[key_enum] = default_value\n",
    "            hyperparams = mapped_hyperparams\n",
    "        \n",
    "        print(f\"KAN HYPERPARAMS: {hyperparams}\")\n",
    "        suggested_hparams = search_space.suggest(hyperparams)\n",
    "        model = MyKan(\n",
    "            INPUT_DIMS,\n",
    "            N_CLASSES,\n",
    "            recall_factor=recall_factor,\n",
    "            hyperparameters=suggested_hparams,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"ESCOLHA DE MODELO ERRADA!\")\n",
    "    return model, suggested_hparams, keys\n",
    "\n",
    "\n",
    "## -----------------------------COLAR NO KAGGLE------------------\n",
    "def main(CHOICE: str):\n",
    "    ###------SEEDS---------###\n",
    "    RAND_SEED = 42\n",
    "    seed_everything(RAND_SEED)\n",
    "    supress_warnings()\n",
    "\n",
    "    AMBIENTE = os.environ[\"AMBIENTE\"]\n",
    "    GPU = True if AMBIENTE in [\"KAGGLE\", \"COLAB\"] else False\n",
    "    ## ----------VARIAVEIS TREINO-----------\n",
    "    cpus = os.cpu_count()\n",
    "    WORKERS = cpus if cpus is not None else 1\n",
    "    NUM_DEVICES = 1 if GPU else 1\n",
    "    NUM_NODES = 1\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 75\n",
    "    PATIENCE = int(EPOCHS * 0.6)\n",
    "    ARTIFACT_PATH = PATH_OUTPUT_DIR / \"artifacts\"\n",
    "    os.makedirs(ARTIFACT_PATH, exist_ok=True)\n",
    "\n",
    "    #### -------- VARIAVEIS DE LOGGING ------------\n",
    "    EXP_NAME = \"PROD_TRAINING\"\n",
    "    RUN_NAME: str | None = f\"PROD_{CHOICE}\"\n",
    "    MLF_TRACK_URI = f\"sqlite:///{PATH_CODE}/mlflow.db\"\n",
    "\n",
    "    mlflow.set_tracking_uri(MLF_TRACK_URI)\n",
    "    mlflow.set_experiment(EXP_NAME)\n",
    "    autolog(log_models=True, checkpoint=True, exclusive=False)\n",
    "\n",
    "    hyperparams = get_best_hyperparameters_from_optuna(CHOICE, MLF_TRACK_URI)\n",
    "\n",
    "    ## ----------VARIAVEIS MODELO-----------\n",
    "    N_CLASSES = 2\n",
    "\n",
    "    datamodule = StrokeDataModule(BATCH_SIZE, WORKERS)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup(\"fit\")\n",
    "\n",
    "    INPUT_DIMS = datamodule.input_dims or -1\n",
    "    assert INPUT_DIMS > 0\n",
    "    recall_factor = datamodule.class_weights\n",
    "    model, _, keys = model_choice(CHOICE, INPUT_DIMS, N_CLASSES, recall_factor, optuna_hyperparams=hyperparams)\n",
    "\n",
    "    _ = model(model.example_input_array)\n",
    "\n",
    "    # loop principal de treinamento\n",
    "    with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        active_run_id = run.info.run_id\n",
    "\n",
    "        mlflow_logger = MLFlowLogger(\n",
    "            experiment_name=EXP_NAME,\n",
    "            tracking_uri=MLF_TRACK_URI,\n",
    "            log_model=True,\n",
    "            run_id=active_run_id,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=PATIENCE, mode=\"min\"\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=EPOCHS,\n",
    "            devices=NUM_DEVICES,\n",
    "            accelerator=\"gpu\" if GPU else \"cpu\",\n",
    "            num_nodes=NUM_NODES,\n",
    "            logger=mlflow_logger,\n",
    "            enable_checkpointing=False,\n",
    "            callbacks=[early_stopping],\n",
    "        )\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        mlflow.log_params(dict(model.hparams))\n",
    "\n",
    "        # Test and log artifacts (useful for the Analysis section)\n",
    "        test_df = datamodule.dataset.original_df.copy()\n",
    "        test_df[\"pred\"] = None\n",
    "        test_df[\"error\"] = None\n",
    "\n",
    "        # Perform one-pass test logic on the full test dataset\n",
    "        _, test_dataset = datamodule.test_dataloader()\n",
    "        return_dict = model.test_step(\n",
    "            test_dataset=test_dataset,\n",
    "            output_df=test_df,\n",
    "        )\n",
    "        test_df = return_dict[\"output_df\"]\n",
    "\n",
    "        # Log test metrics to MLFlow\n",
    "        test_results = model.test_metrics.compute()\n",
    "        mlflow.log_metrics(\n",
    "            {f\"test_{k}\": float(v) for k, v in test_results.items() if v.numel() == 1}\n",
    "        )\n",
    "        model.test_metrics.reset()\n",
    "\n",
    "        name = f\"test_results_{run.info.run_id}.csv\"\n",
    "        path_test_csv = Path(ARTIFACT_PATH, name)\n",
    "        test_df.to_csv(path_test_csv)\n",
    "        mlflow.log_artifact(str(path_test_csv))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\"]  ## MODEL ARCHITECTURE\n",
    "        models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "        for choice in models:\n",
    "            # trains model based on architecture\n",
    "            main(choice)\n",
    " \n",
    "        NAME_RESZIP = \"resultado_kaggle_stroke_normal\"\n",
    "        MLRUNS_FOLDER = Path.cwd() / \"mlruns\"\n",
    "        MLF_TRACK_URI = f\"sqlite:///{PATH_CODE}/mlflow.db\"\n",
    "        ZIP_ROOT = (\n",
    "            PATH_DATASET / \"..\" if os.environ[\"AMBIENTE\"] == \"KAGGLE\" else PATH_DATASET\n",
    "        )\n",
    "\n",
    "        zip_res(MLF_TRACK_URI, MLRUNS_FOLDER, PATH_OUTPUT_DIR, NAME_RESZIP, ZIP_ROOT)\n",
    "        print(\"\\n\", \"=\" * 60)\n",
    "        print(f\"RESULTADOS ZIPADOS {Path(ZIP_ROOT, NAME_RESZIP).resolve()}\")\n",
    "        print(\"=\" * 60, \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    gc.collect()\n",
    "\n",
    "    if os.environ[\"AMBIENTE\"] == \"LOCAL\":\n",
    "        from view.dashboard import see_model\n",
    "\n",
    "        see_model(PATH_DATASET / \"mlflow.db\", PATH_DATASET / \"..\" / \"mlruns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb567387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb81704",
   "metadata": {},
   "source": [
    "## Results Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from typing import Literal\n",
    "from DataProcesser.utils import final_analysis\n",
    "\n",
    "# Saves directly to env output dir\n",
    "output_dir = PATH_OUTPUT_DIR\n",
    "if os.environ[\"AMBIENTE\"] == \"KAGGLE\":\n",
    "    output_dir = PATH_OUTPUT_DIR / \"artifacts\"\n",
    "\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{PATH_CODE}/mlflow.db\")\n",
    "ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\"]  ## MODEL ARCHITECTURE\n",
    "models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "# os.environ[\"OPTUNA\"] = \"True\"\n",
    "\n",
    "SORT_METRIC = \"val_f_beta_avg\"\n",
    "RESIDUAL = True\n",
    "unwanted_metrics = [\"epoch\", \"step\", \"test\"]\n",
    "compare_df, resProcesser = final_analysis(\n",
    "    models, output_dir, SORT_METRIC, unwanted_metrics, residual=RESIDUAL,\n",
    "    exp_name=\"PROD_TRAINING\",\n",
    ")\n",
    "\n",
    "compare_df.to_csv(output_dir / \"classify_results.csv\")\n",
    "print(compare_df.to_string())\n",
    "\n",
    "ser_fbeta = compare_df[SORT_METRIC].sort_values(ascending=False)\n",
    "best_model, fbeta_value = next(ser_fbeta.items())\n",
    "print(f\"BEST MODEL: *{best_model}* WITH F-BETA: {fbeta_value}\\n\")\n",
    "\n",
    "# If true, execute residual analysis of best model's errors\n",
    "if RESIDUAL and False:\n",
    "    resProcesser.fit_predict(str(best_model))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e819eb",
   "metadata": {},
   "source": [
    "## Clear previous trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Define paths to MLflow storage\n",
    "db_path = PATH_CODE / \"mlflow.db\"\n",
    "mlruns_path = PATH_CODE / \"mlruns\"\n",
    "artifacts_dir = PATH_OUTPUT_DIR / \"artifacts\"\n",
    "\n",
    "# Remove MLflow database file\n",
    "if db_path.exists():\n",
    "    os.remove(db_path)\n",
    "    print(f\"Deleted database: {db_path}\")\n",
    "\n",
    "# Remove MLflow artifacts directory\n",
    "if mlruns_path.exists():\n",
    "    shutil.rmtree(mlruns_path)\n",
    "    print(f\"Deleted artifacts folder: {mlruns_path}\")\n",
    "\n",
    "# Remove custom artifacts directory (CSVs generated during training)\n",
    "if artifacts_dir.exists():\n",
    "    shutil.rmtree(artifacts_dir)\n",
    "    print(f\"Deleted custom artifacts: {artifacts_dir}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c39d6",
   "metadata": {},
   "source": [
    "## MLFlow's Dashboard (Only works outside of Kaggle)\n",
    "### Download the training results from Kaggle and paste them into a cloned folder of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cfda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def see_model(database: pathlib.Path, folder: pathlib.Path):\n",
    "    subprocess.Popen(\n",
    "        [\n",
    "            \"mlflow\",\n",
    "            \"ui\",\n",
    "            \"--backend-store-uri\",\n",
    "            f\"sqlite:///{database}\",\n",
    "            \"--default-artifact-root\",\n",
    "            folder,\n",
    "            \"--host\",\n",
    "            \"127.0.0.1\",\n",
    "            \"--port\",\n",
    "            \"5000\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    PATH_RES_ZIPADO = Path(\n",
    "        \"C:\\\\Users\\\\LUIS_FELIPE\\\\Downloads\\\\resultado_kaggle_stroke_1.zip\"\n",
    "    )\n",
    "    DIR = Path(Path.cwd(), PATH_RES_ZIPADO.name.replace(\".zip\", \"\"))\n",
    "    print(f\"DIR: {DIR}\")\n",
    "    if DIR.exists():\n",
    "        shutil.rmtree(DIR)\n",
    "    DIR.mkdir()\n",
    "    shutil.unpack_archive(PATH_RES_ZIPADO, DIR)\n",
    "\n",
    "    print(\"COMECANDO SUBPROCESSO!\\n\")\n",
    "    see_model(DIR / \"mlflow.db\", DIR / \"mlruns\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto-kaggle (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
